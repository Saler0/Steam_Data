from pyspark.sql import SparkSession
from pyspark.sql.functions import col, udf, explode, arrays_overlap, array, lit, current_date, datediff, coalesce, expr, lower, split
from pyspark.sql.types import StringType, DoubleType, IntegerType, ArrayType, StructType, StructField, DateType
from pyspark.ml.feature import HashingTF, IDF, Tokenizer, OneHotEncoder, StringIndexer
from pyspark.ml import Pipeline
from datetime import datetime
import re
from pymongo import MongoClient

# --- 1. Inicializar Spark Session ---
# Asegúrate de que el conector de MongoDB esté correctamente configurado.
# Reemplaza 'org.mongodb.spark:mongo-spark-connector_2.12:3.0.1' con tu versión específica.
spark = SparkSession.builder \
    .appName("SteamAndYouTubeDataIntegration") \
    .config("spark.mongodb.input.uri", "mongodb://localhost:27017/trusted_zone.juegos_steam") \
    .config("spark.mongodb.output.uri", "mongodb://localhost:27017/trusted_zone.final_output_collection") \
    .config("spark.jars.packages", "org.mongodb.spark:mongo-spark-connector_2.12:3.0.1") \
    .getOrCreate()

print("Spark Session iniciada con éxito.")